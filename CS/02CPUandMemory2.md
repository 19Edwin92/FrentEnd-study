## 02 CPU와 메모리 심화

### CPU의 스케쥴링
<br/>

**CPU의 스케쥴링**<br/>

스케쥴링(Scheduling)은 운영체제에서 CPU(Central Processing Unit)의 사용을 관리하는 방법을 의미한다. `CPU 스케쥴링`은 여러 프로세스 또는 스레드가 동시에 실행될 때 이들 간에 CPU 자원을 분배하고, 작업을 스케쥴링하여 효율적으로 실행되도록 조절하는 작업입니다. 

CPU의 스케쥴링은 CU(Control Unit)에서 처리하는 부분으로 명령어의 해석과 실행, 데이터의 처리, 제어 신호의 발생을 담당하며 프로세스나 스레드의 실행 순서를 결정함으로, CPU 자원을 효율적으로 할당하는 역할을 수행한다. CU의 일부분인 스케쥴링 유닛이나 스케줄러는 프로세스 또는 스레드의 우선 선위, 작업의 상태, 입출력 상태, 입출력 요청, 타이머 인터럽트 등 다양한 정보를 기반으로 실행을 관리한다. 

스케쥴링의 결과로, 선택된 작업은 해당 작업의 명령어와 데이터를 처리하는 ALU에 전달되어 실행된다. 스케쥴링은 ALU 자체적으로 수행되지 않고, CU를 통해 ALU에게 어떤 작업을 실행해야 하는지 전달하며, ALU는 그에 따라 실행할 작업을 지시한다. 

<br/>

**CPU의 스케쥴링의 두 가지 유형**<br/>
1. 선점 스케줄링 (Preemptive Scheduling)
- 실행 중인 작업이 다른 작업에 의해 강제로 중단도리 수 있는 방식이고
- 우선 순위가 높은 작업이 도착하거나, 실행 중인 작업이 입출력 요청 등의 이벤트를 기다려야 할 때, 운영체제가 해당 작업의 실행을 중단시키고, CPU를 다른 작업에 할당하는 것이다. 
- 선점 스케줄링은 실시간 시스템에서 많이 사용되며, 우선 순위 기반, 라운드 로빈 등 다양한 알고리즘으로 구현될 수 있다. 
- 실행 중인 작업을 중단시킬 수 있기 때문에 응답 시간을 빠르게 할 수 있지만, 작업 전환에 따른 오버헤드가 발생할 수 있다. 

  |종류|동작방식|
  |:--|:--|
  |우선 순위 기반 스케줄링(Preemptive Priority Scheduling)|현재 실행 중인 작업의 우선 순위를 다른 작업의 우선 순위가 더 높을 경우 중단시키고, CPU를 할당한다. 즉 새로운 작업이 도착하거나, 우선 순위가 변경되었을 때 현재 실행을 중단하고 더 높은 우선 순위의 작업에게 할당한다.|
  |라운드 로빈|작업들에게 일정한 시간을 할당한 후, 순환하며 실행하는 방식이다.|
  |다단계 큐|작업을 여러 개의 큐로 분할하고, 각 큐에 다른 스케줄링 알고리즘을 적용하는 방식, 초기에 가장 높은 우선순위 큐에 할당된 작업은, 현재 실행 중인 큐에서 실행되는 동안 다른 큐로 이동될 수 있다. 이렇개 큐를 분리하고 각 큐에 다른 우선순위 레벨을 부여하며, 높은 우선순위 큐부터 작업을 실행한다. 이때 각 큐는 서로 다른 스케줄링을 적용할 수 있는데, 우선 순위 기반 스케줄링, 라운드 로빈 스케줄링 등이 사용될 수 있음|

2. 비선점 스케줄링 (Non-preemptive Scheduling)
- 실행 중인 작업이 완료될 때까지 다른 작업에 의해 중단되지 않는 방식을 말한다. 
- 우선 순위가 높은 작업이 도착하더라도, 실행 중인 작업이 자발적으로 CPU를 양도하기 전까지 해당 작업이 계속 실시된다. 
- 비선점 스케쥴링은 시분할 시스템에서 주로 사용되며, 먼저 온 순서대로 실행하거나 우선 순위에 따라 실행하는 알고리즘이 적용될 수 있다. 

  |종류|동작방식|
  |:--|:--|
  |우선 순위 기반 스케줄링(Non-preemptive Priority Scheduling)|현재 실행 중인 작업을 다른 작업의 우선 순위가 높아도 중단시키지 않고, 작업이 완료될 때까지 실행한다. 비선점 우선 순위는 스케줄링이 간단하고 예측 가능한 환경에서 사용될 수 있음|
  |FCFS|먼저 도착한 작업이 먼저 실행되는 방식|
  |SJF|실행 시간이 가장 짧은 작업을 우선으로 실행하는 방식|
  |HRN|응답시간과 작업대기 시간을 고려하여 작업의 우선순위를 결정하는 알고리즘으로, 각 작업에 대해 응답 시간 대기 시간을 비율로 계산하여 우선 순위로 사용한다. 즉 HRN은 작업의 응답시간이 짧고 대기 시간이 적은 작업에 높은 우선순위를 부여하여 실행한다. 응답시간을 고려하기에 응답성이 개선되지만, 계산 비용이 높고, 작업 대기 시간이나 서비스 시간이 긴 작업에 분리|

  <br/>

**CPU의 스케쥴링과 용어**<br/>

  |종류|설명|
  |:--|:--|
  |스케쥴링의 단위|스케줄링 알고리즘이 작업을 관리하는 최소 단위, 프로세스, 스레드, 태스크 같은 단위를 지칭한다.|
  |프로세스|실행 중인 프로그램의 인스턴스, 운영 체제에 의해 관리되는 작업 단위, 각 프로세스는 독립된 메모리 영역을 가지며, 별도의 주소 공간을 할당받아 동작한다. |
  |스레드|프로세스 내에서 실행되는 실행 단위로, 하나의 프로세스는 여러 개의 스레드를 가질 수 있다. 그러기에 각 스레드는 프로세스의 자원을 공유할 수 있다.|
  |테스크|작업의 단위로, 실행 가능한 독립적인 단위를 말한다. 프로세스 또는 스레드와 유사하지만, 실행 가능한 코드와 그에 필요한 데이터 및 리소스를 포함하여, 일련된 작업을 수행하는 단위를 말한다.|
  |오버헤드|스케쥴링에 따르는 부가적인 비용 또는 시스템 부담으로, 작업 전환, 문백 교환 등의 추가적인 작업이나 리소스 사용을 가리킨다. 성능과 응답성에 영향을 주기에 오버헤드는 최소화 되어야 한다|
  |CPU 사용률|실제로 CPU가 작업을 처리하는 비율을 나탠다, 알고리즘은 CPU 사용률을 최대화하고, 유휴 시간을 최소화하여, CPU의 활용도를 향상시키는 것을 목표로 한다|
  |기아현상| 우선 순위가 낮은 작업이 계속뒤로 밀려서 실행되지 못하여 리소스 접근이 제한되는 현상을 말한다.|
  |CPU Burst|작업이 CPU를 사용하여 연산을 수행하는 시간을 의미|
  |I/O Burst| 작업이 입출력 장치와 상호작용하거나 입출력 작업을 수행하는 시간을 의미한다.|
  

<br/>

**CPU의 스케쥴링의 진행상태**<br/>

  |종류|설명|
  |:--|:--|
  |준비|프로세스가 실행될 준비가 완료되었고, CPU를 할당받기 위해 대기하고 있는 상태|
  |대기|프로세스가 CPU와 상호 작용하기 위해 입출력 작업 등을 기다리고 있는 상태|
  |수행|수행 상태는 프로세스가 CPU를 할당받아 실행되고 있는 상태, CPU Burst를 수행하는 상태|
  |종료|프로세스의 실행이 완료되고, 모든 작업이 종료된 상태|

  프로세스는 준비 상태에서 대기 상태로 이동하고, 입출력 작업이 완료되면 다시 준비 상태로 전환된다. 준비 상태에서 CPU를 할당받으면 수행 상태로 전환되어 CPU Burst를 수행하고, 작업이 모두 완료되면 종료 상태로 전환된다.



<details>
<summay>정리전 내용들</summay>

**CPU 심화, 스케쥴링**
- 프로세서 : 프로그램을 실행해주는 주체 `ex. 카카오톡`
- 쓰레드 : 작업을 처리해주는 주제 `ex. 메시지 발송`
- CPU를 잘 사용하기 위해서는 프로세서를 잘 배정해야 한다. 이는 한정된 자원으로 최대한 성능을 이끌어내야 하기 때문이다. 
- 운영체제(OS)는 실행 대기중인 프로그램(프로세서)들에게 CPU 자원 배정을 적절히 하여 시스템의 성능을 끌어올릴 수 있게 됩니다. 

- `오버헤드 최소화` : 프로세서가 필요한 자원보다 더 많이 사용하는 것, `투머치`
- `사용률 최대화` : `알잘딱깔쎈`
- `공평하게 분배, 기아현상` : 프로세스가 자원할당을 못받아서 대기하고 있는 상태 

**CPU 심화, 스케쥴링 단위**
1. CPU Brust : 프로세서의 사용중에 연속적으로 CPU를 사용하는 구간, 실제 스케쥴링의 단위
2. I/O Brust : 입력대기, 출력 대기의 시간 
3. `스케쥴링 알고리즘의 평가` : CPU 이용률(작업처리하난 시간의 비율), 처리량(시간당 처리하는 프로세서의 수),  총 처리시간, 대기시간, 응답시간
 
**CPU 심화, 스케쥴링 종류**
1. 선점 스케쥴링 : OS가 나서서 CPU사용권을 '선점'하고, 특정 요건에 따라 각 프로세스의 요청이 있을 때 프로세스에게 분배하는 방식, OS가 필요에 따라 프로세스의 요청이 있을 때 강제로 회수할 수 있다. 

    - `우선순위 스케줄링` : 미리 주어진 프로세스의 우선순위에 따라서 할당, 그러나 우선순위가 낮은 프로세스는 할당되지 않기도 하는 문제가 있을 수 있으며, 대기사간이 높은 기아 현상이 발생될 수 있다.  
    - `라운드로빈` :정해진 시간 할당량 만큼 프로세스를 할당한 뒤, 작업이 끝난 프로세스는 준비완료 큐(순환 큐)의 가장 마지막에 가서 재할당을 기다리는 방법, `빈번한 문맥 전환(Context Switching)이 발생`
    - `다단계 큐` : 준비완료 큐를 여러개의 큐로 분류하여 각 큐가 각각 다른 스케쥴링 알고리즘을 가지는 방식. 메모리 크기, 우선순위, 유형 등 프로세스의 특성에 따라 하나의 큐에 영구적으로 할당

2. 비선점 스케쥴링 : 어떤 프로세스가 CPU를 할당받으면 그 프로세스가 종료되거나, 입출력 요구가 발생하여 자발적으로 중지될 때 까지 계속 실행되도록 보장하는 방법있다. 

    - 순서대로 처리되는 공정성, 응답시간을 예상
    - 호출빈도가 낮고, 문백교환에 의한 오버헤드가 적다.
    - 그러나 CPU 사용시간이 긴 프로세스가 다른 프로세스들을 대기시킬 수 있다는 단점 

    - `First Come , First Serve` : FIFO큐(먼저 입력된것 먼저 출력), 큐에 도착한 순서대로 
      - 호위효과(Convoy Effect) : 프로세서가 선점되면, 나머지 프로세서들이 대기하는 것 
    - `Shorted Job First` : 버스트 타임이 가장 짦은, 최단작업을 우선 스케쥴링 하는 알고리즘
      - 대기 시간이 가장 작다. 
      - 다음 프로세서의 버스트시간을 계산하기 어렵다는 단점이 있다. 
    - `Highest Response-ratio Next` : 우선순위를 계산하여 점유 불평등을 보완  

**CPU 스케줄링 정리**
1. 준비상태 : 예, 카카오톡을 띄워서 메시지를 입력하고 있을 때
2. 대기상태 : 카카오톡이 비활성화 되어있거나, 가만히 상대방의 답장을 기다릴때
3. 수행상태 : 사용자가 메시지를 발송하거나 상대방의 메시지를 수신할때
4. 종료상태 : 카카오톡 프로그램을 종료 


**메모리 심화, 캐시란?**

    메모리 계층은 경제성 때문이었다. 

- `캐시` : 데이터를 저장해 놓는 임시서장소로, CPU(MMU)가 메인 메모리에서 데이터를 읽어오는 작업을 처리할 때, 캐시가 중간에서 한번 더 메인메모리의 데이터를 복사해두는 거라고 보면 된다.
- `병목현상 개선` : 빠른 장치와 느린 장치 사이의 속도 차이를 줄이기 위한 메모리 
- 캐시는 계층과 계층 사이의 속도차이를 해결하기 위한 임시 저장소이다. 
- `레지스터` : CPU의 연산을 위한 저장소 
- `SRAM` : 말그대로 임시저장소 역할을 수행하기 구분합니다. 

**메모리 심화, 캐시와 지역성**
1. 시간 지역성 : 최근 사용한 데이터에 다시 접근하려는 특성으로, for문의 i에 해당된다. 

```javascript 
for(let i=0; i<5; i++){
	console.log(i) // 0 1 2 3 4
}
```

2. 공간 지역성 : 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성으로, arr 배열 원소에 대한 공간을 의미한다. 

```javascript 
let arr = [];

for(let i=0; i<5; i++){
	arr.push(i)
}
// arr = [0,1,2,3,4]
```

**메모리 심화, 캐시 getter, Miss**
1. `캐시히트` : 캐시에서 원하는 데이터를 찾는 것, 위치도 가깝고 CPU 내부버스를 기반으로 작동
2. `캐시미스` : 해당 데이터가 없기에, 주메모리로 가서 데이터를 찾아오는 것, 
3. `캐시매핑` : 캐시의 히트률을 높이는 것이다. 
  - (1) 직접매핑 : 주소값으로 매핑, 충돌이 발생
  - (2) 연관매핑 : 순서를 일치하지 않고 관련성으로 매핑, 충돌은 적지만, 모든 블록을 탐색 느림
  - (3) 집한 연관 매핑 : 순서일치, 집합을 둬서 저장, 블록화, 검색이 효율적이다. 

**메모리 심화, 메모리 할당**
1. 연속할당 : 
  - 고정분할(내부 단편화 발생, 메모리보다 작은 프로그램이 작은 경우, 공간이 많이 비는 것)
  - 가변분할 방식(메모리보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생)
2. 불연속 할당 : 운영체제에서 여러 개의 작업을 효율적으로 수행하는 부분에서 불연석 할당방식을 사용
  - 페이징 : 페이지 단위로 나누어, 메모리의 서로 다른 위치에 프로세서를 할당, 빈데이터의 크기가 균일하지 않은 문제가 사라지지만, 주소 변환이 복잡하다. 
  - 세그멘테이션 : 의미단위로 나누어, 공유와 보안 측면이 좋다. 빈데이터 크가가 균일하지 않은 문제 발생
  - 페이지드 세그멘테이션 : 공유나 보안은 세그먼트로, 문리적 메모리는 페이지로 나눈다. 

**메모리 심화, 메모리 할당, 페이지 교체 알고리즘**
1. 오프라인 알고리즘 : 입력 데이터를 모두 가지고 있는 알고리즘, 실행시간 공간 사용량을 예측할 수 있다. 
2. 시간기반 알고리즘
  - FIFO(First In First Out) : 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법, 구현이 간단하지만, 오래된 데이터가 최근에 사용된 데이터와 비슷한 경우에 성능이 저하될 수 있습니다.
  - LRU(Least Recently Used) : 참조가 가장 오래된 페이지를 교체하는 방법, 오랜된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야한다는 문제점 발생하지만, 캐시 히트(hit)율을 높일 수 있습니다. 
  - NUR(Not Used Recently) : clock 알고리즘 최근사용여부를 0,1로 표시하여 교체하는 방법
    - LRU : 데이터를 사용할 때마다 최근 사용 시간을 갱신
    - NUR : 사용하지 않은 데이터를 주기적으로 스캔하여 최근 사용 여부를 판단
3. 빈도기반 알고리즘 
  - LFU(Least Frequently Used) : 가장 참조 횟수가 적은 페이지를 교체, LFU 알고리즘은 일부 데이터가 빈번하게 사용되는 경우에는 성능 저하가 발생할 수 있습니다.


**리액트의 상태관리와 메모리**

리액트의 상태관리는 메모리 부분에서 중요한 요소이다. 대표적으로 `리덕스`와 `리액트쿼리` 라이브러리가 있고 이 둘은 메모리 측면에서 상태관리의 방식이 다르다. 간략하게 리덕스는 전역 상태를 관리하는 중앙 집중식 스토어를 사용하고, 리액트 쿼리는 캐시를 사용하여 컴포넌트 트리 내에서 데이터를 쿼리하고 관리한다. 

  - 컴포넌트 트리 : 컴포넌트들이 계층적으로 구성되는 구조
  - 쿼리 : 데이터를 요청하고 가져오는 작업으로, 컴포넌트가 필요한 데이터를 요청하고 해당 데이터를 캐싱하여 재사용할 수 있게 해준다. 
  - `컴포넌트 트리 내에서 데이터를 쿼리하고` : 컴포넌트는 필요한 데이터에 대한 쿼리를 수행하고, 이전에 캐싱된 데이터를 사용하여 성능을 향상시키고 중복된 요청을 피할 수 있게 된다. 

1. 리덕스와 메모리 : 리덕스의 상태는 주 메모리에 저장되며, 상태 변경 시 해당 상태를 사용하는 모든 컴포넌트가 업데이트 된다. 

  그러나 캐시에 대한 부분이 없기에 다른 컴포넌트로 이동한 후에 동일한 요청을 수행할 경우, 리덕스는 요청을 다시 실행한다. 이를 통해 중복된 네트워크 요청이 발생될 수 있고, 필요하지 않은 데이터 요청을 실행할 수 있다는 점을 의미한다. 그러기에 네트워크 요청과 관련된 성능 개선을 위해서는 캐싱, 메모이제이션 등의 방법을 추가로 사용하여 중복 요청을 피하고 불필요한 네트워트 요청을 최소화하는 작업이 필요하다. 

  - ThunkAPI 기준, Reselect와 같은 라이브러리를 사용하면 메모이제이션을 활용
  - ThunkAPI를 사용하면 리덕스에서 네트워크 요청을 수행할 수 있지만, 리액트 쿼리는 네트워크 요청에 특화된 상태 관리 라이브러리로써 더 효율적일 수 있습니다.
  - 리덕스와 ThunkAPI는 상태 관리와 비동기 작업을 위해 강력한 도구입니다. 그러나 네트워크 요청에 초점을 두는 경우에는 리액트 쿼리가 더 많은 기능과 편의성을 제공할 수 있습니다. 따라서 프로젝트의 요구 사항과 상황에 맞게 리액트 쿼리를 활용하여 네트워크 요청을 처리하는 것이 좋을 수 있습니다.

2. 리액트쿼리와 메모리 : 리액트의 공식 상태관리 라이브러리인데, 캐시를 사용하여 데이터를 저장하고 관리한다. 리액트 쿼리의 캐시는 컴포넌트 트리 내에서 데이터를 효율적으로 쿼리하고 캐싱하여 성능을 최적화한다. 컴포넌트는 데이터를 구독하고 필요한 경우 쿼리를 실행하여 데이터를 가져온다. 다른 컴포넌트에서 동일한 데이터에 대한 쿼리를 수행할 때 재사용될 수 있다. 

    이때 주의할 점은 해당 컴포넌트와 그 하위 컴포넌트 간에 데이터를 공유할 수 있도록 동작한다는 것이다. 그러나 형제 컴포넌트 간에는 직접적인 데이터 공유가 가능하지 않다. 이를 위해서는 데이터를 상위 컴포넌트의 상태로 끌어올리고, 이를 props로 하위 컴포넌트에 전달하여 형제 컴포넌트 간에 데이터 공유를 구현해야 한다. 

    이때, URL이 다르면 새로운 데이터 요청을 수행하는데, 같은 URL에 대한 동일한 요청에 대해서는 리액트 쿼리의 퀴리의 캐시에서 이전에 요청한 데이터를 가져온다. 즉 다른 컴포넌트로 이동했다가 해당 컴포넌트로 돌아오면, 리액트 쿼리는 이전에 쿼리한 데이터를 캐시에서 가져와서 사용한다. 이를 통해 중복 요청을 효과적으로 방지하고, 불필요한 네트워크 요청을 줄여 성능을 개선하는 데 도움이 된다. 
</details>